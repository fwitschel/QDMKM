{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
     {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fwitschel/QDMKM/blob/main/notebooks/QDMKM_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Execute this code only if in colab\n",
        "if 'COLAB_GPU' in os.environ:\n",
        "  print(\"Executing in Colab!\")\n",
        "  # Cloning GitHub repository\n",
        "  !git clone https://github.com/fwitschel/QDMKM.git\n",
        "  %cd QDMKM\n"
      ],
      "metadata": {
        "id": "qRHf7ZEBbs5-",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f37bad0c-c06c-454c-9969-90aba88a3c53"
      },
      "execution_count": 1,
      "outputs": []
    },
	{
      "cell_type": "markdown",
      "metadata": {
        "id": "LyvaSbo_shy-"
      },
      "source": [
        "We install some libraries that we will need later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rqHYkRjADu5B",
        "outputId": "3fdc5fcd-4958-4c1f-cf1b-dd171f8654b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.3.29)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.0.0)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: langchain-anthropic in /usr/local/lib/python3.12/dist-packages (0.3.19)\n",
            "Collecting groq\n",
            "  Downloading groq-0.31.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.75)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.16)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (4.55.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (1.16.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (0.34.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (4.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: anthropic<1,>=0.64.0 in /usr/local/lib/python3.12/dist-packages (from langchain-anthropic) (0.66.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1,>=0.64.0->langchain-anthropic) (0.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (1.1.8)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence_transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Downloading groq-0.31.0-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.4/131.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.31.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-community pypdf sentence_transformers faiss-cpu langchain-anthropic groq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wzTj7gKsRMt"
      },
      "source": [
        "I've put the csv file into Google Drive. To make it work for yourself, make sure to do the same. If you put it into a folder, you need to adapt the path in the second row of code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_aGgXCFD4BX",
        "outputId": "6dce74ce-49a3-476b-bbb2-94557693bcce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzM17s7Kp72a"
      },
      "source": [
        "We read the input file into a so-called dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkcRXL5iD4jf",
        "outputId": "74b3324d-bfa3-429b-af9f-7fc7337f497d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               sender                 receiver  \\\n",
            "0   student42@MBFH.ch      my_msc_dean@MBFH.ch   \n",
            "1   student21@MBFH.ch      my_msc_dean@MBFH.ch   \n",
            "2   student84@MBFH.ch  former_msc_dean@MBFH.ch   \n",
            "3  student168@MBFH.ch      my_msc_dean@MBFH.ch   \n",
            "4  student336@MBFH.ch      my_msc_dean@MBFH.ch   \n",
            "\n",
            "                                    subject  first_date notice_weeks  \\\n",
            "0                       Re: late submission  2019-06-16            1   \n",
            "1  Re: extend deadline because of sickness?  2020-06-14            1   \n",
            "2                     Re: thesis submission  2016-07-01          NaN   \n",
            "3                 Re: request for extension  2021-05-10            6   \n",
            "4                             Re: extension  2019-05-16            5   \n",
            "\n",
            "                   tags                                           all_text  \\\n",
            "0  sickness certificate  Dear Ms Smith, unfortunately, we cannot accept...   \n",
            "1  sickness certificate  Dear Mr Doe, your request to extend the deadli...   \n",
            "2                   job  Dear Ms Gross, I am sorry, but you will have t...   \n",
            "3                   job  Dear Mr Klein, we have decided to extend the d...   \n",
            "4                 child  Dear Ms Little, unfortunately we cannot grant ...   \n",
            "\n",
            "  attachment  \n",
            "0        yes  \n",
            "1        yes  \n",
            "2         no  \n",
            "3        yes  \n",
            "4         no  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/cases-emails.csv', sep=\",\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPsf4E0Mt7SN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1F3eO8apZnt"
      },
      "source": [
        "In the input file, each case is represented by one row. We create one Document object for each case that contains, as textual content (to be transformed and stored as embedding vectors) the subject of the initial email, followed by the entire text of the conversation. As metadata, we keep the email address of the sender and the notice with which the extension was requested. Later, it can be useful to have quick access to this metadata..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-5-rsZmEXde",
        "outputId": "3c82d980-fda7-4092-f21a-021a154eabe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='Re: late submission Dear Ms Smith, unfortunately, we cannot accept your request for deadline extension. Since your sickness occurred during a non-critical period of your thesis work and was comparatively short, there was enough time to resolve issues resulting from it. We are looking forward to receiving your thesis submission on June 21st. Best regards, The Dean. ---- Dear Prof. Dean, please find attached the certificate for my sickness. Hoping for a positive decision, best regards, Jane Smith. ---- Dear Ms Smith, could you please send us a medical certificate for your sick period. Please note that this does not imply that we will grant the extension, it is just a routine request. Thanks and best regards, The Dean. --- Dear Prof. Dean, I am writing to you to ask for a deadline extension of 1 week for my master thesis. In February, I had a really bad flu from which it took me two weeks to recover. I feel that I am still suffering from the consequences since my whole thesis plan got mixed up during that period - where I was in a great flow before analysing the literature, I felt I had to start from scratch after my sickness. Now, I am behind, but feel that an additional week would allow me to deliver good results. I hope you understand my situatiuon. Thank you and best regards, Jane' metadata={'source': 'student42@MBFH.ch', 'notice': '1'}\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.documents import Document\n",
        "docs = []\n",
        "for index, row in df.iterrows():\n",
        "    sender = row['sender']\n",
        "    subject = row['subject']\n",
        "    text = subject + \" \" + row['all_text']\n",
        "    notice = row['notice_weeks']\n",
        "    document = Document(\n",
        "        page_content=text,\n",
        "        metadata={\"source\": sender,\"notice\":notice}\n",
        "    )\n",
        "    docs.append(document)\n",
        "\n",
        "print(docs[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKr94dwNpJRN"
      },
      "source": [
        "We take an embeddings model and use it to create embeddings vectors for our email conversations. When you print such an embedding vector, you see that it is just a bunch of numbers..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bnXWSeOH1rm",
        "outputId": "5c1c8a7b-499a-4df2-a8c0-8b2dd0d64e2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4200763017.py:6: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  bge_embeddings = HuggingFaceBgeEmbeddings(\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.06024384871125221, 0.026430655270814896, 0.0225814338773489, 0.013069206848740578, 0.01753048226237297, -0.0023633234668523073, 0.03058656118810177, 0.028281155973672867, -0.02356867864727974, -0.025400156155228615, 0.014191539026796818, -0.027386901900172234, -0.0051805428229272366, -0.009107922203838825, 0.028404168784618378, 0.015285535715520382, 0.004506242927163839, -0.0001287022460019216, -0.011500483378767967, 0.056939512491226196, -0.011474188417196274, -0.003694898448884487, -0.004475079011172056, -0.01813863031566143, -0.02838337980210781, -0.012660231441259384, -0.0020878424402326345, -0.03936571255326271, -0.026432769373059273, -0.19615942239761353, -0.04876245558261871, -0.023337749764323235, -0.00040942514897324145, -0.02391272597014904, 0.024079613387584686, -0.00774333905428648, -0.02413586899638176, 0.02551259659230709, -0.027522554621100426, 0.03140414506196976, 0.04504132270812988, 0.02439049445092678, -0.03522004932165146, -0.031253401190042496, -0.011611481197178364, -0.056151848286390305, -0.035815007984638214, -0.03684268891811371, 0.027664240449666977, 0.0009356721420772374, 0.006254333537071943, -0.03842170163989067, -0.002641490427777171, 0.07056684046983719, 0.005658915266394615, 0.03066388890147209, 0.0306350439786911, 0.027856117114424706, -0.011591375805437565, 0.02677980437874794, 0.023518994450569153, 0.020675761625170708, -0.21525250375270844, 0.055452827364206314, 0.023508340120315552, 0.009804435074329376, -0.04363831877708435, -0.029153972864151, 0.01947811245918274, 0.05285079404711723, -0.0367523729801178, 0.005825121887028217, -0.03087090142071247, 0.08910543471574783, 0.03165517374873161, 0.02655760757625103, 0.03025519661605358, -0.03174242377281189, 0.04524856060743332, 0.013628996908664703, -0.006706705316901207, -0.006383091676980257, 0.010382632724940777, -0.03098876029253006, -0.02575918845832348, 0.002393267350271344, -0.00780872069299221, -0.0007823694031685591, 0.01938164234161377, -0.000550413504242897, 0.023786840960383415, -0.0767238587141037, 0.02438342198729515, 0.01889672875404358, -0.08145888894796371, -0.04493046924471855, 0.030120007693767548, 0.0006003255839459598, -0.06764933466911316, 0.6340795159339905, -0.044939640909433365, 0.034219153225421906, 0.007281008642166853, -0.0486530140042305, 0.013771902769804, 0.01677400805056095, 0.017975660040974617, -0.013794807717204094, -0.008916130289435387, -0.005659305490553379, 0.0010918317129835486, 0.03222765773534775, 0.05168265476822853, -0.0327371209859848, 0.015777409076690674, 0.031694814562797546, 0.04282141476869583, 0.028090810403227806, 0.00958037655800581, -0.032774411141872406, -0.018650654703378677, 0.020233791321516037, 0.04327326640486717, -0.018560610711574554, -0.03746426850557327, -0.09838666021823883, -0.013050828129053116, 0.04606063291430473, 0.041861630976200104, -0.018819324672222137, 0.07729043811559677, -0.034756869077682495, -0.043988462537527084, -0.015654942020773888, 0.0006719550001434982, 0.011705388315021992, -0.0071000647731125355, -0.03244011849164963, 0.024062126874923706, -0.028934858739376068, -0.019355779513716698, -0.07124075293540955, -0.03003016486763954, 0.0023864461109042168, -0.038958072662353516, 0.08477438241243362, -0.025015471503138542, 0.022290995344519615, -0.009378532879054546, -0.022925056517124176, -0.0336761400103569, 0.02006390504539013, -0.07189343124628067, -0.004670328926295042, 0.050166357308626175, 0.014975456520915031, 0.04877505451440811, 0.006681713275611401, -0.0101453997194767, -0.00960471574217081, -0.019143540412187576, -0.04182710126042366, -0.02733413316309452, 0.05471810698509216, 0.0491190031170845, -0.06595759838819504, 0.0064747086726129055, 0.010613503865897655, 0.06376929581165314, -0.020186077803373337, 0.058083757758140564, -0.015141643583774567, 0.027261191979050636, -0.01990102045238018, 0.063345767557621, 0.003197247860953212, -0.008346011862158775, 0.001994993072003126, 0.019054360687732697, 0.03156827390193939, 0.03406010568141937, -0.020570306107401848, -0.008960538543760777, -0.0008244006894528866, 0.028854141011834145, -0.0772545337677002, -0.028334368020296097, 0.0034743156284093857, -0.008305453695356846, -0.013480289839208126, -0.05989275127649307, -0.018336698412895203, -0.04718584194779396, -0.008520961739122868, -0.015276270918548107, -0.03837551921606064, 0.030975285917520523, -0.05546363815665245, 0.008159407414495945, -0.01718445122241974, 0.02725202403962612, 9.381058043800294e-05, -0.006059636361896992, 0.029218308627605438, 0.015590006485581398, 0.032726310193538666, 0.042248621582984924, -0.026265645399689674, 0.04569893702864647, 0.018268758431077003, -0.024797772988677025, -0.015011127106845379, 0.04718828573822975, -0.0013834548881277442, -0.0025857375003397465, 0.039357684552669525, 0.007752224337309599, 0.05060931667685509, 0.020628254860639572, 0.02604656107723713, 0.036481186747550964, 0.005328139755874872, -0.014979399740695953, -0.17227451503276825, 0.008328758180141449, -0.016972485929727554, -0.059883493930101395, 0.03330353647470474, -0.015672815963625908, 0.04230774566531181, -0.030911250039935112, -0.0006177781033329666, 0.021107029169797897, 0.07065273076295853, 0.012710887007415295, -0.018905984237790108, -0.03700052201747894, -0.0053955139592289925, 0.017477575689554214, 0.014817299321293831, -0.02583896927535534, 0.03055870346724987, -0.031890448182821274, -0.014901510439813137, -0.0019954948220402002, -0.03652617335319519, -0.042954906821250916, 0.0028887430671602488, -0.029378617182374, 0.14571300148963928, 0.024987274780869484, 0.02431073598563671, -0.01752210035920143, 0.011620153672993183, 0.008446491323411465, 0.038546834141016006, -0.14632266759872437, -0.011459971778094769, 0.008417344652116299, -0.010723910294473171, -0.02273300103843212, -0.016540471464395523, -0.024232372641563416, -0.02841920591890812, 0.03500157222151756, 0.03212755545973778, -0.012658277526497841, -0.035865094512701035, 0.01920834183692932, -0.0023488877341151237, 0.0031432982068508863, 0.005736013874411583, 0.04883665218949318, -0.003467393107712269, -0.02544451504945755, 0.021536201238632202, 0.019070308655500412, 0.006397208198904991, -0.0018040607683360577, -0.08654405176639557, 0.03464369848370552, -0.020565234124660492, 0.04817601293325424, 0.004653919022530317, -0.009433732368052006, 0.022606592625379562, -0.010304764844477177, -0.028435690328478813, 0.006213448941707611, 0.0010329594369977713, -0.04031841456890106, -0.010833575390279293, -0.01570804975926876, 0.019153239205479622, 0.0563066303730011, -0.015107063576579094, -0.0021430281922221184, 0.035167187452316284, -0.024740727618336678, 0.027547379955649376, -0.0022840166930109262, 0.001197007135488093, -0.03252217546105385, 0.019321605563163757, -0.07653526961803436, 0.0060514346696436405, 0.03313194587826729, 0.0025808745995163918, 0.05405358225107193, 0.004156184382736683, 0.034868624061346054, -0.015100963413715363, -0.005636006128042936, -0.023055877536535263, -0.0072060879319906235, -0.012157673016190529, 0.04376915842294693, 0.03499063476920128, -0.0020981745328754187, -0.2615169584751129, 0.03987446054816246, 0.037140052765607834, 0.02067047357559204, 0.003352696541696787, -0.004203189630061388, -0.007097326219081879, -0.01784917153418064, -0.06356915831565857, 0.03495330363512039, 0.02196587063372135, 0.05245150253176689, 0.017802145332098007, 0.012300561182200909, 0.003654252039268613, 0.01043931394815445, 0.02662564627826214, -0.04003638029098511, 0.0016559215728193521, -0.010220656171441078, 0.026741305366158485, -0.022331858053803444, 0.14588963985443115, -0.003484778106212616, -0.01816737838089466, 0.00950042437762022, 0.008896494284272194, 0.015645956620573997, 0.03093245066702366, -0.024661339819431305, 0.014953536912798882, -0.007111910730600357, -0.00820663571357727, -0.028616588562726974, 0.016509726643562317, -0.03407825902104378, -0.031517237424850464, 0.051123861223459244, -0.0022266258019953966, -0.010335837490856647, 0.004115925170481205, 0.0024203064385801554, -0.016592927277088165, -0.007130247075110674, -0.005636228714138269, 0.008927038870751858, -0.01642620377242565, -0.02349543385207653, -0.024202736094594002, 0.017876658588647842, -0.004722281824797392, -0.016202490776777267, -0.028702884912490845, 0.018201518803834915, 0.0036718291230499744, 0.055180516093969345, 0.027948465198278427, -0.01013805903494358, 0.006568808574229479, -0.04373517632484436, 0.0038302734028548002, -0.03923036903142929, 0.0010951971635222435, 0.022943461313843727, -0.00043202616507187486]\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "\n",
        "model_name = \"BAAI/bge-small-en\"\n",
        "model_kwargs = {\"device\": \"cpu\"}\n",
        "encode_kwargs = {\"normalize_embeddings\": True}\n",
        "bge_embeddings = HuggingFaceBgeEmbeddings(\n",
        "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
        ")\n",
        "\n",
        "chunk_texts = list(map(lambda d: d.page_content, docs))\n",
        "embeddings = bge_embeddings.embed_documents(chunk_texts)\n",
        "print(embeddings[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuT_t0W6o-6y"
      },
      "source": [
        "We store the embedding vectors in a vector database (FAISS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8u0K_6FIZPdJ"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "text_embedding_pairs = zip(chunk_texts, embeddings)\n",
        "db = FAISS.from_embeddings(text_embedding_pairs, bge_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPTgNEt9cfWQ"
      },
      "source": [
        "Here, we describe the new case that needs to be decided / solved. We then use the description to retrieve emails with the 3 most similar cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhcaoCF9ZU2B",
        "outputId": "87071b43-cc6a-4945-d74c-e4f8aace8a04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Re:late submission? Dear Ms Orange, you will be granted an extension of two weeks. We understand the critically of the point in time when your sickness occurred. Please submit your thesis on August 4th, midnight. Regards, The Dean ---- Hi Dean, as you can see from the attached medical certificate, I was sick for more than two weeks and would like to ask for a deadline extension for my master thesis. The sickness started three weeks ago when I was starting to write up my results. There were also two (out of 5) evaluation interviews that I had to cancel because of the sickness. This means that I was unable to finish the thesis. Hoping for your understanding, best regards, Olivia\n",
            "Re:master thesis Dear Mr Brown, Although your certificate does not cover the entire period in which you say you were sick, one can conclude from your documents that the sickness must have started earlier. Because of that long period, we can grant you an extension of two weeks. Please submit your thesis by August 4th, midnight. Regards, The Dean ---- Dear Mr Dean, could you please grant me an extension of my master thesis deadline? As I told you in class today, I was sick and unable to work on the thesis for almost two months. I attach the medical documentation. Two or three weeks more to work on the thesis would be great! Thanks and kind regards, Bob Brown\n",
            "Re: late submission Dear Ms Smith, unfortunately, we cannot accept your request for deadline extension. Since your sickness occurred during a non-critical period of your thesis work and was comparatively short, there was enough time to resolve issues resulting from it. We are looking forward to receiving your thesis submission on June 21st. Best regards, The Dean. ---- Dear Prof. Dean, please find attached the certificate for my sickness. Hoping for a positive decision, best regards, Jane Smith. ---- Dear Ms Smith, could you please send us a medical certificate for your sick period. Please note that this does not imply that we will grant the extension, it is just a routine request. Thanks and best regards, The Dean. --- Dear Prof. Dean, I am writing to you to ask for a deadline extension of 1 week for my master thesis. In February, I had a really bad flu from which it took me two weeks to recover. I feel that I am still suffering from the consequences since my whole thesis plan got mixed up during that period - where I was in a great flow before analysing the literature, I felt I had to start from scratch after my sickness. Now, I am behind, but feel that an additional week would allow me to deliver good results. I hope you understand my situatiuon. Thank you and best regards, Jane\n"
          ]
        }
      ],
      "source": [
        "topk = 3\n",
        "query = \"A student discovered that she was pregnant soon after starting the thesis proposal. Towards the end of her thesis, the pregancy became complicated and she had to take leave. A sickness certificate is available.\"\n",
        "#query = \"A student needs more time because he had to take over more responsibilities for a new project / mission. His employer assigned him as a project leader and he could not refuse it.\"\n",
        "\n",
        "contexts = db.similarity_search(query, k=topk)\n",
        "\n",
        "for i in range(topk):\n",
        "  print(contexts[i].page_content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8BTPPEbcNiA"
      },
      "source": [
        "Here, we connect to an LLM at Groq. To make it work, please get yourself an API key for GROQ and store it as a key on the left side of this notebook...!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "def llm(groq_client, prompt):\n",
        "  chat_completion = groq_client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        }\n",
        "    ],\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "  )\n",
        "\n",
        "  return chat_completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "qZLFmUZ_YPPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "groq_client = Groq(\n",
        "    api_key=userdata.get('GROQ_API_KEY')\n",
        ")"
      ],
      "metadata": {
        "id": "x9JPwWjLYuJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, you instruct the Large Language Model what to do:\n",
        "\n",
        "* In the \"system\" part of the prompt, you explain the general task, including the\n",
        "context (i.e. the retrieved information) that the system should rely on. You can pass the content of the retrieved emails by putting \"{context}\" into this part of the prompt\n",
        "* In the \"query\" part of the prompt, you give instruction to make a decision about the new case (as introduced already above, before the retrieval)"
      ],
      "metadata": {
        "id": "Mk4C7brMbDzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context = '\\n\\n'.join(list(map(lambda c: c.page_content, contexts)))\n",
        "prompt = f\"\"\"You are an assistant that helps a study dean to decide about students' request for extending the deadline of their master theses.\n",
        "        The current case is described as follows: {query}.\n",
        "        To decide about the current case, the following historical emails seem to be relevant: {context}. Please make a suggestion whether or not\n",
        "        to grant the deadline extension, including a justification that is based on the given context! If possible, please include quotes from the historical emails\"\"\"\n",
        "print(llm(groq_client, prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVV2T_ufZiNs",
        "outputId": "622b7b68-61ae-47a0-ac1c-9cbad99639e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the provided historical emails and the current case, I suggest granting the deadline extension to the student. \n",
            "\n",
            "The student's situation is unique and challenging, as she discovered her pregnancy soon after starting her thesis proposal and faced complications towards the end, necessitating a leave of absence. The availability of a sickness certificate supports her claim, similar to the cases of Olivia and Bob Brown, where medical documentation was used to justify the extension.\n",
            "\n",
            "As seen in the email to Ms. Orange, the Dean has previously granted an extension of two weeks, stating, \"We understand the critically of the point in time when your sickness occurred.\" In this case, the student's pregnancy and subsequent complications occurred during a critical period of her thesis work, making it difficult for her to complete the thesis on time.\n",
            "\n",
            "Moreover, the Dean has shown flexibility in granting extensions when the sickness has significantly impacted the student's work, as in the case of Bob Brown, where the Dean states, \"Although your certificate does not cover the entire period in which you say you were sick, one can conclude from your documents that the sickness must have started earlier.\" This flexibility suggests that the Dean considers the overall impact of the sickness on the student's work, rather than just the duration of the sickness.\n",
            "\n",
            "In contrast, the Dean denied the extension to Ms. Smith, stating, \"Since your sickness occurred during a non-critical period of your thesis work and was comparatively short, there was enough time to resolve issues resulting from it.\" However, the current student's situation is different, as her pregnancy and complications occurred during a critical period and had a significant impact on her ability to complete the thesis.\n",
            "\n",
            "Given these considerations, I suggest granting the deadline extension to the student. As the Dean previously stated to Olivia, \"Please submit your thesis on August 4th, midnight,\" a similar extension of two weeks could be granted, allowing the student to complete her thesis without undue stress or pressure.\n",
            "\n",
            "Justification quote: \"We understand the critically of the point in time when your sickness occurred\" (email to Ms. Orange), highlighting the importance of considering the timing and impact of the sickness on the student's thesis work.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TWFT5Ew7ZlN0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}